{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPsPha0XQJbS1dzsthqD1f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JurijZ/ai-zip/blob/main/recursive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "w8kOkkcvRyDl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Preparation (100 words)\n",
        "text = \"\"\"\n",
        "Artificial intelligence is a branch of computer science that aims to create intelligent machines.\n",
        "It has become an essential part of the technology industry. Research associated with artificial\n",
        "intelligence is highly technical and specialized. The core problems of artificial intelligence\n",
        "include programming computers for certain traits such as knowledge reasoning problem solving\n",
        "perception learning planning and the ability to move and manipulate objects. Knowledge engineering\n",
        "is a core part of AI research. Machines can often act and react like humans only if they have\n",
        "abundant information relating to the world. Artificial intelligence must have access to objects\n",
        "categories properties and relations.\n",
        "\"\"\"\n",
        "words = text.split()[:100]\n",
        "vocab = sorted(list(set(words)))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
        "target_indices = torch.tensor([word_to_ix[w] for w in words], dtype=torch.long)"
      ],
      "metadata": {
        "id": "_P8F_1EGR64C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 2. Recursive Transformer Model\n",
        "class RecursiveTransformerCompressor(nn.Module):\n",
        "    def __init__(self, vocab_size, seq_len, d_model, nhead, num_iterations):\n",
        "        super().__init__()\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        # This embedding acts as the \"address\" or \"query\" for the memory\n",
        "        self.pos_embedding = nn.Embedding(seq_len, d_model)\n",
        "\n",
        "        # The recursive block (shared weights)\n",
        "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 2,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self):\n",
        "        # We don't pass data in; we generate from the internal position weights\n",
        "        x = self.pos_embedding(torch.arange(100).to(self.pos_embedding.weight.device))\n",
        "        x = x.unsqueeze(0) # Add batch dimension\n",
        "\n",
        "        # Recursion: The same weights are used num_iterations times\n",
        "        for _ in range(self.num_iterations):\n",
        "            x = self.transformer_layer(x)\n",
        "\n",
        "        return self.output_layer(x).squeeze(0)"
      ],
      "metadata": {
        "id": "AdVXiFLPSAoZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Hyperparameters for Compression\n",
        "# To prove compression, we keep d_model small.\n",
        "D_MODEL = 64\n",
        "N_HEAD = 4\n",
        "ITERATIONS = 5 # How many times to loop through the same weights\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "model = RecursiveTransformerCompressor(VOCAB_SIZE, 100, D_MODEL, N_HEAD, ITERATIONS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "pk9khQQtSEA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o61sJ8tBRqM2",
        "outputId": "fd6b71f7-c9df-49cc-c842-0e2cf2fff0f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Storing information in 44877 recursive parameters...\n",
            "Epoch    0 | Loss: 4.5100 | Accuracy: 2%\n",
            "Epoch  300 | Loss: 0.0167 | Accuracy: 100%\n",
            "Epoch  600 | Loss: 0.0051 | Accuracy: 100%\n",
            "Epoch  900 | Loss: 0.0024 | Accuracy: 100%\n",
            "Epoch 1200 | Loss: 0.0015 | Accuracy: 100%\n"
          ]
        }
      ],
      "source": [
        "# 4. Training Loop (Overfitting/Memorizing)\n",
        "print(f\"Storing information in {sum(p.numel() for p in model.parameters())} recursive parameters...\")\n",
        "\n",
        "for epoch in range(1201):\n",
        "    optimizer.zero_grad()\n",
        "    output = model()\n",
        "    loss = criterion(output, target_indices)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 300 == 0:\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct = (predicted == target_indices).sum().item()\n",
        "        print(f\"Epoch {epoch:4d} | Loss: {loss.item():.4f} | Accuracy: {correct}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Restoration\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_output = model()\n",
        "    restored_indices = torch.argmax(final_output, dim=1)\n",
        "    restored_text = [ix_to_word[idx.item()] for idx in restored_indices]\n",
        "\n",
        "print(\"\\n--- Restored Text ---\")\n",
        "print(\" \".join(restored_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrUeWRRlSII_",
        "outputId": "86b531a7-7367-49e9-8e8c-45fef6692c52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Restored Text ---\n",
            "Artificial intelligence is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry. Research associated with artificial intelligence is highly technical and specialized. The core problems of artificial intelligence include programming computers for certain traits such as knowledge reasoning problem solving perception learning planning and the ability to move and manipulate objects. Knowledge engineering is a core part of AI research. Machines can often act and react like humans only if they have abundant information relating to the world. Artificial intelligence must have access to objects categories properties and\n"
          ]
        }
      ]
    }
  ]
}